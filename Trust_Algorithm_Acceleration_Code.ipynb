{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaItlTGZaxfC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "License - Any one can use the code or specific part for any purpose with acknowledgement of work of original Authors of this code. \n",
        "\n",
        "Trust Algorithm is parallerlized on GPU for graph Matching. Achieved speeds are between 150-300, on K140. Speedups might vary. \n",
        "\n",
        "The graph data - the data generated in this program is an artificially generated graph which is bidirectonal in nature , however real practical graphs can be more complex than that. \n",
        "However, the code serves as a good example of how to accelerate an heuristic beam search algorithm on GPU using Cuda and python. \n",
        "\n",
        "Authors of the code - \n",
        "1. Xuan Zhang\n",
        "2. Dushyant Singh Udawat\n",
        "3. Leo franco Soto\n",
        "'''\n",
        "\n",
        "\n",
        "# Importing all the libraries that will be required.\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "import heapq\n",
        "import random\n",
        "import time\n",
        "import cupy as cp\n",
        "from numba import cuda\n",
        "import numba\n",
        "\n",
        "p = \"\"\n",
        "q = \"\"\n",
        "\n",
        "# return the normalized distance between two words\n",
        "def word_distance(p : str, q : str) -> float:\n",
        "    # place holder, now we use simple way to calculate the distance between two string\n",
        "    n = len(p)\n",
        "    m = len(q)\n",
        "    #print(n, m)\n",
        "    d = np.zeros([n + 1, m + 1], dtype=int)\n",
        "    for j in range(m + 1):\n",
        "        d[0][j] = j\n",
        "    for i in range(1, n + 1):\n",
        "        d[i][0] = i\n",
        "        for j in range(1, m + 1):\n",
        "            d[i][j] = min(d[i][j - 1], d[i - 1][j]) + 1\n",
        "            d[i][j] = min(d[i][j], d[i - 1][j - 1] + (p[i - 1] != q[j - 1]))\n",
        "\n",
        "#    print(d)\n",
        "    return d[n][m] / max(n, m)\n",
        "\n",
        "#p = input()\n",
        "#q = input()\n",
        "\n",
        "#print(word_distance(p, q))\n",
        "\n",
        "lack = 0.\n",
        "eps = 1e-7\n",
        "\n",
        "\n",
        "# this is normal max-matching algorithm - max matching is n-p hard. We use quadratic solver. \n",
        "def max_matching_algo(w : np.array, n: int) -> float:\n",
        " #   print(\"matching....\")\n",
        "    lx = np.zeros([n + 2], dtype = float)\n",
        "    ly = np.zeros([n + 2], dtype = float)\n",
        "    visited_x = np.zeros([n + 2], dtype=int)\n",
        "    visited_y = np.zeros([n + 2], dtype=int)\n",
        "    link_y = np.zeros([n + 2], dtype=int)\n",
        "    global lack\n",
        "\n",
        "    def find(x: int) -> bool:\n",
        "        global lack\n",
        "        visited_x[x] = True\n",
        "        for y in range(1, n + 1):\n",
        "            if not visited_y[y]:\n",
        "                tmp = lx[x] + ly[y] - w[x][y]\n",
        "                if tmp < eps:\n",
        "                    visited_y[y] = True\n",
        "                    if link_y[y] == 0 or find(link_y[y]):\n",
        "                        link_y[y] = x\n",
        "                        return True\n",
        "                else:\n",
        "                    lack = min(lack, tmp)\n",
        "        return False\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            lx[i] = max(lx[i], w[i][j]) # init\n",
        "\n",
        "    for x in range(1, n + 1):\n",
        "        while True:\n",
        "            visited_x = np.zeros([n + 2], dtype=int)\n",
        "            visited_y = np.zeros([n + 2], dtype=int)\n",
        "            lack = 100000\n",
        "            if find(x): break\n",
        "            for i in range(1, n + 1):\n",
        "                if visited_x[i]:\n",
        "                    lx[i] -= lack\n",
        "                if visited_y[i]:\n",
        "                    ly[i] += lack\n",
        "    total_value = 0.\n",
        "\n",
        "    for y in range(1, n + 1):\n",
        "        total_value += w[link_y[y]][y]\n",
        "\n",
        "  #  print(\"matching Complete!\")\n",
        "    return total_value\n",
        "\n",
        "\n",
        "# A recursive Max matching algorithm function is not cuda implementable , so here is a non recursive version of the same. \n",
        "def Non_recursive_max_matching_algo(w : np.array, n: int) -> float:\n",
        " #   print(\"matching....\")\n",
        "    lx = np.zeros([n + 2], dtype = float)\n",
        "    ly = np.zeros([n + 2], dtype = float)\n",
        "    visited_x = np.zeros([n + 2], dtype=int)\n",
        "    visited_y = np.zeros([n + 2], dtype=int)\n",
        "    link_y = np.zeros([n + 2], dtype=int)\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            lx[i] = max(lx[i], w[i][j]) # init\n",
        "\n",
        "    for x in range(1, n + 1):\n",
        "      while True:\n",
        "        lack_GPU = 100000\n",
        "        visited_x = np.zeros([n + 2], dtype=int)\n",
        "        visited_y = np.zeros([n + 2], dtype=int)\n",
        "\n",
        "        pos = 1\n",
        "        stack_x = np.zeros(n, dtype = int)\n",
        "        stack_y = np.zeros(n, dtype = int)\n",
        "        stack_x[1] = x\n",
        "        stack_y[1] = 0\n",
        "        Label = False\n",
        "        while pos > 0:\n",
        "          cur_x = stack_x[pos]\n",
        "          cur_y = stack_y[pos]\n",
        "          Recur_label = False\n",
        "          if Label:\n",
        "            link_y[cur_y] = cur_x\n",
        "            pos -= 1\n",
        "            continue\n",
        "          visited_x[cur_x] = True\n",
        "          for y in range(cur_y + 1, n + 1):\n",
        "            if not visited_y[y]:\n",
        "              tmp_GPU = lx[cur_x] + ly[y] - w[cur_x][y]\n",
        "              if tmp_GPU < eps:\n",
        "                  visited_y[y] = True\n",
        "                  if link_y[y] == 0:\n",
        "                    link_y[y] = cur_x\n",
        "                    pos -=1\n",
        "                    Label = True\n",
        "                  else:\n",
        "                    stack_y[pos] = y\n",
        "                    pos += 1\n",
        "                    stack_x[pos] = link_y[y]\n",
        "                    stack_y[pos] = 0\n",
        "                    Recur_label = True\n",
        "                  break\n",
        "              else:\n",
        "                  lack_GPU = min(lack_GPU, tmp_GPU)\n",
        "          if Recur_label == False and Label == False: pos -= 1\n",
        "\n",
        "        if Label: break\n",
        "\n",
        "        for i in range(1, n + 1):\n",
        "            if visited_x[i]:\n",
        "                lx[i] -= lack_GPU\n",
        "            if visited_y[i]:\n",
        "                ly[i] += lack_GPU\n",
        "    total_value = 0.\n",
        "\n",
        "    for y in range(1, n + 1):\n",
        "        total_value += w[link_y[y]][y]\n",
        "\n",
        "  #  print(\"matching Complete!\")\n",
        "    return total_value\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are calculating hop scores for each pairs of graph nodes. When triggering this function in GPU we will call as many threads as there are node pairs in the graph.\n",
        "@cuda.jit\n",
        "def GPU_calculate_hop_score_i_j(gpu_data_n, gpu_word_distance, gpu_data_graph_adj_matrix, gpu_template_graph_adj_matrix, gpu_data_node_name_list, gpu_template_node_name_list, gpu_one_hop_score_table):\n",
        "    #   print(\"matching....\")\n",
        "    id_x, id_y = cuda.grid(2)\n",
        "    id_x += 1\n",
        "    id_y += 1\n",
        "\n",
        "    if id_x > gpu_data_n:\n",
        "      return\n",
        "    n = gpu_data_graph_adj_matrix[id_x][0]\n",
        "    m = gpu_template_graph_adj_matrix[id_y][0]\n",
        "    #print(n, m)\n",
        "    max_nm = max(n, m)\n",
        "    if max_nm == 0:\n",
        "      gpu_one_hop_score_table[id_x][id_y] = 0.5 * gpu_word_distance[id_x][id_y]\n",
        "    else:\n",
        "      cnt = 0.\n",
        "      cnt_n = 0\n",
        "      # w = cuda.local.array(shape = (52, 52), dtype=numba.float64)\n",
        "      # for x in range(1, n + 1):\n",
        "      #  p = gpu_data_graph_adj_matrix[id_x][x]\n",
        "      #  for y in range(1, m + 1):\n",
        "      #    q = gpu_template_graph_adj_matrix[id_y][y]\n",
        "      #    w[x][y] = gpu_word_distance[p][q]\n",
        "\n",
        "      lx = cuda.local.array(80, dtype = numba.float64)\n",
        "      ly = cuda.local.array(80, dtype = numba.float64)\n",
        "      visited_x = cuda.local.array(80, dtype=numba.boolean)\n",
        "      visited_y = cuda.local.array(80, dtype=numba.boolean)\n",
        "      link_y = cuda.local.array(80, dtype=numba.int64)\n",
        "      for i in range(1, max_nm + 1):\n",
        "        lx[i] = ly[i] = 0\n",
        "      for i in range(1, max_nm + 1):\n",
        "          for j in range(1, max_nm + 1):\n",
        "              lx[i] = max(lx[i], gpu_word_distance[gpu_data_graph_adj_matrix[id_x][i]][gpu_template_graph_adj_matrix[id_y][j]]) # init\n",
        "\n",
        "      for x in range(1, max_nm + 1):\n",
        "        while True:\n",
        "          lack_GPU = 100000\n",
        "          for i in range(1, n + 1):\n",
        "            visited_x[i] = 0\n",
        "            visited_y[i] = 0\n",
        "\n",
        "          pos = 1\n",
        "          stack_x = cuda.local.array(80, dtype = numba.int64)\n",
        "          stack_y = cuda.local.array(80, dtype = numba.int64)\n",
        "          stack_x[1] = x\n",
        "          stack_y[1] = 0\n",
        "          Label = False\n",
        "          while pos > 0:\n",
        "            cur_x = stack_x[pos]\n",
        "            cur_y = stack_y[pos]\n",
        "            Recur_label = False\n",
        "            if Label:\n",
        "              link_y[cur_y] = cur_x\n",
        "              pos -= 1\n",
        "              continue\n",
        "            visited_x[cur_x] = True\n",
        "            for y in range(cur_y + 1, max_nm + 1):\n",
        "              if not visited_y[y]:\n",
        "                tmp_GPU = lx[cur_x] + ly[y] - gpu_word_distance[gpu_data_graph_adj_matrix[id_x][cur_x]][gpu_template_graph_adj_matrix[id_y][y]]\n",
        "                if tmp_GPU < eps:\n",
        "                    visited_y[y] = True\n",
        "                    if link_y[y] == 0:\n",
        "                      link_y[y] = cur_x\n",
        "                      pos -=1\n",
        "                      Label = True\n",
        "                    else:\n",
        "                      stack_y[pos] = y\n",
        "                      pos += 1\n",
        "                      stack_x[pos] = link_y[y]\n",
        "                      stack_y[pos] = 0\n",
        "                      Recur_label = True\n",
        "                    break\n",
        "                else:\n",
        "                    lack_GPU = min(lack_GPU, tmp_GPU)\n",
        "            if Recur_label == False and Label == False: pos -= 1\n",
        "\n",
        "          if Label: break\n",
        "\n",
        "          for i in range(1, max_nm + 1):\n",
        "              if visited_x[i]:\n",
        "                  lx[i] -= lack_GPU\n",
        "              if visited_y[i]:\n",
        "                  ly[i] += lack_GPU\n",
        "\n",
        "      max_matching_value = 0.\n",
        "      for y in range(1, max_nm + 1):\n",
        "        max_matching_value += gpu_word_distance[gpu_data_graph_adj_matrix[id_x][link_y[y]]][gpu_template_graph_adj_matrix[id_y][y]]\n",
        "\n",
        "      gpu_one_hop_score_table[id_x][id_y] = 0.5 * gpu_word_distance[id_x][id_y] + 0.5 * max_matching_value/max_nm\n",
        "\n",
        "# these Node/Edge class are for general Node/Edge, not for specific nodes\n",
        "\n",
        "\n",
        "#A node have a name on it and a weight on it, now we consider the weight as a part of the name.\n",
        "\n",
        "# Specifications of the search processes. Changing them will lead to change in how the matching algorithm works. \n",
        "DETAIL_RESULT = False\n",
        "HEAP_SIZE = 1000\n",
        "SEARCH_RANGE = 1000\n",
        "HASHING_NUM =  2**16 + 1\n",
        "HASHING_TOTAL =  2**32 + 1\n",
        "ADJ_MAX = 50\n",
        "#print(HASHING_TOTAL, HASHING_NUM)\n",
        "Hashing_A = 2\n",
        "Hashing_B = 3\n",
        "TEMPLATE_GRAPH_MAX_SIZE = 10\n",
        "cuda.detect()\n",
        "\n",
        "\n",
        "# this is the Node class of the graph. It contains a name, and value, it is identified by the name. attr stores combination of name and value. \n",
        "class Node:\n",
        "    name = \"\"\n",
        "    value = 0\n",
        "    __attr = \"\"\n",
        "\n",
        "    def __init__(self, name=\"\", value=0):\n",
        "        self.name = name\n",
        "        self.value = value\n",
        "        self.__attr = self.name + \"|\" + str(self.value)\n",
        "\n",
        "    def name_distance(self, other) -> float:\n",
        "        return word_distance(self.name, other.name)\n",
        "\n",
        "    def attr(self):\n",
        "        return self.__attr\n",
        "\n",
        "    def change_name(self):\n",
        "        # todo\n",
        "        pass\n",
        "\n",
        "\n",
        "# An edge contain the \"name\" of two node, the name for itself and the value/capacity/weight on the edge\n",
        "class Edge:\n",
        "    def __init__(self, name=\"\", from_node_name: str = \"\", to_node_name: str = \"\", value=0):\n",
        "        self.name = name\n",
        "        self.from_node_name = from_node_name\n",
        "        self.to_node_name = to_node_name\n",
        "        self.value = value\n",
        "        self.__attr = name + '|' + self.from_node_name + '|' + self.to_node_name + '|' + str(self.value)\n",
        "\n",
        "    def attr(self):\n",
        "        return self.__attr\n",
        "\n",
        "# This is a update function which will set the values of all the variablles correctly to make everything ready for the next iteration of GPU_trust_searching_matrix_type\n",
        "@cuda.jit\n",
        "def GPU_search_update_history_position(cur_level, p, tmp_value, tmp_history, searching_history, searching_value, nn):\n",
        "  i = cuda.grid(1)\n",
        "  searching_value[cur_level][nn - i - 1] = tmp_value[p[i]]\n",
        "  if tmp_history[p[i]][1] != 0 and tmp_history[p[i]][1] != 0:\n",
        "    #print(type(searching_history))\n",
        "    searching_history[cur_level][nn - i - 1][0] = tmp_history[p[i]][0]\n",
        "    searching_history[cur_level][nn - i - 1][1] = tmp_history[p[i]][1]\n",
        "    searching_history[cur_level][nn - i - 1][2] = tmp_history[p[i]][2]\n",
        "\n",
        "# This is the function that finds the best matching at each of the steps in Beam search algorithm\n",
        "@cuda.jit\n",
        "def GPU__trust_searching_matrix_type(DATA_NODE_SIZE : int, TEMPLATE_NODE_SIZE : int, current_lvl, GPU_one_hop_score_table, GPU_template_graph_adj_matrix, GPU_data_graph_adj_matrix,searching_history, searching_value, new_history, new_value):\n",
        "  matching_info = cuda.local.array(shape=50, dtype=numba.int64)\n",
        "  adj_check = cuda.local.array(shape=50, dtype=numba.int64)\n",
        "  check_index = cuda.grid(1)\n",
        "  searching_index = cuda.grid(1)\n",
        "  tmp : int = 0\n",
        "  for p in range(current_lvl, 0, -1):\n",
        "    check_index, x, y = searching_history[p][check_index]\n",
        "    if x == 0 or y == 0:\n",
        "      return\n",
        "    matching_info[y] = x\n",
        "  for tt in range(1, TEMPLATE_NODE_SIZE + 1):\n",
        "    if matching_info[tt] != 0:\n",
        "      for i_index in range(1, GPU_data_graph_adj_matrix[matching_info[tt]][0] + 1):\n",
        "        i = GPU_data_graph_adj_matrix[matching_info[tt]][i_index]\n",
        "        already_matched = False\n",
        "        for check_y in range(1, TEMPLATE_NODE_SIZE + 1):\n",
        "          if matching_info[check_y] == i:\n",
        "            already_matched = True\n",
        "            break\n",
        "          adj_check[check_y] = 0\n",
        "        if already_matched: continue\n",
        "        check_sum = 0\n",
        "        for check_x_index in range(1, GPU_data_graph_adj_matrix[i][0] + 1):\n",
        "          check_x = GPU_data_graph_adj_matrix[i][check_x_index] \n",
        "          for check_y in range(0, TEMPLATE_NODE_SIZE + 1):\n",
        "            if check_x == matching_info[check_y]:\n",
        "              adj_check[check_y] = 1\n",
        "              check_sum += 1\n",
        "        for j in range(1, TEMPLATE_NODE_SIZE + 1):\n",
        "          if matching_info[j] != 0: continue\n",
        "          check_flag = True\n",
        "          check_sum_tmp = check_sum\n",
        "          for check_y_jndex in range(1, GPU_template_graph_adj_matrix[j][0] + 1):\n",
        "            check_y = GPU_template_graph_adj_matrix[j][check_y_jndex]\n",
        "            if matching_info[check_y] == 0:\n",
        "              continue\n",
        "            if adj_check[check_y] == 0:\n",
        "              check_flag = False\n",
        "              break\n",
        "            else:\n",
        "              check_sum_tmp -= 1\n",
        "          if check_flag and check_sum_tmp == 0:\n",
        "              # matching_info[j] = i\n",
        "              # if self.check_hashing_matrix(matching_info, template_graph.n):\n",
        "              #     print(\"YES\")\n",
        "              tmp_value = searching_value[current_lvl][searching_index] + GPU_one_hop_score_table[i][j]\n",
        "              s = int(searching_index * ADJ_MAX * TEMPLATE_NODE_SIZE + tmp)\n",
        "              new_value[s] = tmp_value\n",
        "              new_history[s][0] = int(searching_index)\n",
        "              new_history[s][1] = int(i)\n",
        "              new_history[s][2] = int(j)\n",
        "              tmp += 1\n",
        "              if tmp >= 50 * TEMPLATE_NODE_SIZE:\n",
        "                return\n",
        "              #self.updating_new_instance_matrix_base(new_value, current_lvl + 1, searching_index,i, j)\n",
        "\n",
        "# def name_distance(self, other) -> float:\n",
        "#    return word_distance(self.name, other.name)\n",
        "\n",
        "#GraphNode contains the information of a \"node\" and its relationship in the graph\n",
        "class GraphNode:\n",
        "    def __init__(self, node: Node, node_index=-1):\n",
        "        self.node_index = node_index\n",
        "        self.node_info = node\n",
        "        self.adjc_edge: Dict[str, GraphEdge] = {}\n",
        "        self.adjc_node: Dict[str, GraphNode] = {}\n",
        "\n",
        "    def similarity_score(self, other) -> float:\n",
        "        return Node.name_distance(self.node_info, other.node_info)\n",
        "\n",
        "    def one_hop_distance(self, other) -> float:\n",
        "        n = len(self.adjc_edge)\n",
        "        m = len(other.adjc_edge)\n",
        "        max_nm = max(n, m)\n",
        "        if max_nm == 0:\n",
        "            return 0.5 * self.similarity_score(other)\n",
        "        cnt = 0.\n",
        "        cnt_n = 0\n",
        "        t = np.zeros([max_nm + 1, max_nm + 1], dtype=float)\n",
        "        for i in self.adjc_edge:\n",
        "            edge_i = self.adjc_edge.get(i)\n",
        "            cnt_n += 1\n",
        "            if edge_i.from_node == self:\n",
        "                node_i = edge_i.to_node\n",
        "            else:\n",
        "                node_i = edge_i.from_node\n",
        "            cnt_m = 0\n",
        "            for j in other.adjc_edge:\n",
        "                cnt_m += 1\n",
        "                edge_j = other.adjc_edge.get(j)\n",
        "                if edge_j.from_node == other:\n",
        "                    node_j = edge_j.to_node\n",
        "                else:\n",
        "                    node_j = edge_j.from_node\n",
        "\n",
        "                t[cnt_n][cnt_m] = GraphNode.similarity_score(node_i, node_j) #+ 0.5 * GraphEdge.name_distance(edge_i, edge_j)\n",
        "        max_matching_value = max_matching_algo(t, max_nm) # get the max bipartite matching\n",
        "        return 0.5 * self.similarity_score(other) + 0.5 * max_matching_value/max_nm\n",
        "\n",
        "\n",
        "\n",
        "# GraphEdge connects two nodes in the graph, with name and value on the edge.\n",
        "class GraphEdge:\n",
        "    def __init__(self, from_node: GraphNode, to_node: GraphNode, name: str = \"\", value: int = 0):\n",
        "        self.name = name\n",
        "        self.from_node = from_node\n",
        "        self.to_node = to_node\n",
        "        self.value = value\n",
        "        self.connect_num = (from_node.node_index, to_node.node_index)\n",
        "        #  self.is_directed = is_directed\n",
        "\n",
        "    def name_distance(self, other) -> float:\n",
        "        return word_distance(self.name, other.name)\n",
        "\n",
        "    def distance(self, other) -> float:\n",
        "        return max(0.5 * GraphNode.similarity_score(self.from_node, other.from_node) + 0.5 * GraphNode.similarity_score(self.to_node, other.to_node),\n",
        "                   0.5 * GraphNode.similarity_score(self.from_node, other.to_node) + 0.5 * GraphNode.similarity_score(self.to_node, other.from_node))\n",
        "\n",
        "\n",
        "# for simplicity we assume it's a totally undirected graph for now\n",
        "class Graph:\n",
        "    # n, m are node_size, edge_size\n",
        "    def __init__(self, n : int, m : int, node_list: List[Node], edge_list: List[Edge]):\n",
        "        # here the node in the edge_list is corresponding to the node in the node_list\n",
        "        self.n = 0\n",
        "        self.m = m\n",
        "        self.hashing_table = set()\n",
        "        self.node_list : Dict[str, GraphNode] = {}\n",
        "        self.heap_size = 0\n",
        "        self.H: List[(int, int)] = []\n",
        "        self.heap_info_list = [{}]\n",
        "        # adj_matrix and indexing is 1-based\n",
        "        self.adj_matrix = np.zeros([n + 2, ADJ_MAX + 2], dtype=int)\n",
        "\n",
        "        self.word_distance_table = np.zeros((n + 2, ADJ_MAX + 2), dtype= float)\n",
        "        self.searching_history = np.zeros([0], dtype= int)\n",
        "        self.searching_value = np.zeros([0], dtype= float)\n",
        "\n",
        "        self.node_name_list = [\"-1\"]\n",
        "        self.one_hop_score_table_old = None\n",
        "        self.one_hop_score_table_CPU = None\n",
        "        self.one_hop_score_table = None\n",
        "\n",
        "        # build_node\n",
        "        for node in node_list:\n",
        "            self.node_name_list += [node.name]\n",
        "            if self.node_list.get(node.name) is None:\n",
        "                self.n += 1\n",
        "                self.node_list[node.name] = GraphNode(node, self.n)\n",
        "        # build_edge\n",
        "        self.edge_list : Dict[str, GraphEdge] = {}\n",
        "        for edge in edge_list:\n",
        "            self.build_edge(edge)\n",
        "\n",
        "        self.one_hope_score_dict: Dict[str, float] = {}\n",
        "\n",
        "    def build_edge(self, edge: Edge):\n",
        "        if self.edge_list.get(edge.attr()) is not None:\n",
        "            return\n",
        "\n",
        "        from_node_name = edge.from_node_name\n",
        "        to_node_name = edge.to_node_name\n",
        "\n",
        "        # find GraphNode in the Graph Node list, if there is none, create a new Graph Node for it.\n",
        "        p = self.node_list.get(from_node_name)\n",
        "        if p is None:\n",
        "            print(\"new_node_found, Error!\")\n",
        "            self.n += 1\n",
        "            p = GraphNode(Node(from_node_name), self.n)\n",
        "            self.node_list[from_node_name] = p\n",
        "        q = self.node_list.get(to_node_name)\n",
        "        if q is None:\n",
        "            print(\"new_node_found, Error!\")\n",
        "            self.n += 1\n",
        "            q = GraphNode(Node(to_node_name), self.n)\n",
        "            self.node_list[to_node_name] = q\n",
        "\n",
        "        # create an GraphEdge and add it into the edge list\n",
        "        adding_edge = GraphEdge(p, q, edge.name, edge.value)\n",
        "        self.edge_list[edge.attr()] = adding_edge\n",
        "\n",
        "        # adding the adjacency edge to its two GraphNodes\n",
        "        # here we first consider no duplicate edges\n",
        "        p.adjc_edge[edge.attr()] = adding_edge\n",
        "        p.adjc_node[q.node_info.name] = q\n",
        "        q.adjc_edge[edge.attr()] = adding_edge\n",
        "        q.adjc_node[p.node_info.name] = p\n",
        "\n",
        "\n",
        "        # create adj_matrix\n",
        "        self.adj_matrix[p.node_index][0] += 1\n",
        "        self.adj_matrix[q.node_index][0] += 1\n",
        "        self.adj_matrix[p.node_index][self.adj_matrix[p.node_index][0]] = q.node_index\n",
        "        self.adj_matrix[q.node_index][self.adj_matrix[q.node_index][0]] = p.node_index\n",
        "\n",
        "    # building an array of distances on class for easy access\n",
        "    def build_word_distance(self, template_graph):\n",
        "      for i in range(1, self.n+1):\n",
        "        for j in range(1, template_graph.n+1):\n",
        "          self.word_distance_table[i][j] = word_distance(self.node_name_list[i],template_graph.node_name_list[j])\n",
        "\n",
        "    # building one_hop scores for each pair of nodes and saving for easier access.\n",
        "    def GPU_build_node_based_one_hop_score(self, template_graph):\n",
        "        self.one_hop_score_table = np.zeros([self.n + 2, template_graph.n + 2], dtype=float)\n",
        "        data_size = self.n \n",
        "        tmp_size = template_graph.n\n",
        "        num_i = 0\n",
        "        gpu_word_distance = cuda.to_device(self.word_distance_table)\n",
        "        gpu_template_graph_adj_matrix = cp.array(template_graph.adj_matrix)\n",
        "        gpu_data_graph_adj_matrix = cp.array(self.adj_matrix)\n",
        "        gpu_data_node_name_list = cuda.to_device(self.node_name_list)\n",
        "        gpu_template_node_name_list = cuda.to_device(template_graph.node_name_list)\n",
        "        gpu_one_hop_score_table = cp.array(self.one_hop_score_table)\n",
        "        GPU_calculate_hop_score_i_j[(int(self.n/8)+1,template_graph.n),(8,1)](self.n, gpu_word_distance, gpu_data_graph_adj_matrix, gpu_template_graph_adj_matrix, gpu_data_node_name_list, gpu_template_node_name_list, gpu_one_hop_score_table)\n",
        "\n",
        "        self.one_hop_score_table = cp.asnumpy(gpu_one_hop_score_table)\n",
        "\n",
        "    # \n",
        "    def OLD_build_node_based_one_hop_score(self, template_graph):      \n",
        "        self.one_hop_score_table_old = np.zeros([self.n + 2, template_graph.n + 1], dtype=float)\n",
        "        data_size = len(self.node_list)\n",
        "        tmp_size = len(template_graph.node_list)\n",
        "        num_i = 0\n",
        "      #  print(self.node_name_list)\n",
        "      #  for i in self.node_list:\n",
        "      #    print(self.node_list[i].node_index, i)\n",
        "        for i in self.node_list:\n",
        "            node_i = self.node_list.get(i)\n",
        "            #print(i, '.....')\n",
        "            for j in template_graph.node_list:\n",
        "                node_j = template_graph.node_list.get(j)\n",
        "                tmp_value = GraphNode.one_hop_distance(node_i, node_j)\n",
        "    \n",
        "                # print(node_i.node_index, node_j.node_index, tmp_value)\n",
        "\n",
        "                # self.one_hope_score_dict[node_i.node_info.name + '|' + node_j.node_info.name] = tmp_value\n",
        "\n",
        "                self.one_hop_score_table_old[node_i.node_index][node_j.node_index] = tmp_value\n",
        "\n",
        "    def CPU_build_node_based_one_hop_score(self, template_graph):\n",
        "        self.one_hop_score_table = np.zeros([self.n + 2, template_graph.n + 2], dtype=float)\n",
        "        data_size = len(self.node_list)\n",
        "        tmp_size = len(template_graph.node_list)\n",
        "        num_i = 0\n",
        "        for i in range(1, self.n + 1):\n",
        "        #  print(self.node_name_list[i],\"....\")\n",
        "          for j in range(1, template_graph.n + 1):\n",
        "            n = self.adj_matrix[i][0]\n",
        "            m = template_graph.adj_matrix[j][0]\n",
        "            #print(n, m)\n",
        "            max_nm = max(n, m)\n",
        "            if max_nm == 0:\n",
        "              self.one_hop_score_table[i][j] = 0.5 * self.word_distance_table[i][j]\n",
        "            else:\n",
        "              cnt = 0.\n",
        "              cnt_n = 0\n",
        "              t = np.zeros([max_nm + 1, max_nm + 1], dtype=float)\n",
        "              for x in range(1, n + 1):\n",
        "                p = self.adj_matrix[i][x]\n",
        "                for y in range(1, m + 1):\n",
        "                  q = template_graph.adj_matrix[j][y]\n",
        "                  t[x][y] = self.word_distance_table[p][q]\n",
        "              max_matching_value = max_matching_algo(t, max_nm)\n",
        "\n",
        "              self.one_hop_score_table_CPU[i][j] = 0.5 * word_distance(self.node_name_list[i], template_graph.node_name_list[j]) + 0.5 * max_matching_value/max_nm\n",
        "\n",
        "    def simple_hashing(self,fitting_detail):\n",
        "        tmp = 0.\n",
        "        for j in fitting_detail:\n",
        "            i = fitting_detail.get(j)\n",
        "            tmp = tmp + float(i) * float(j)\n",
        "        if tmp in self.hashing_table:\n",
        "            return False\n",
        "        else:\n",
        "            self.hashing_table.add(tmp)\n",
        "            return True\n",
        "\n",
        "    def search_clear_start(self):\n",
        "        self.H = []\n",
        "        self.hashing_table = set()\n",
        "        self.heap_info_list = [{}]\n",
        "        self.heap_size = 0\n",
        "\n",
        "    #####################\n",
        "\n",
        "    # BELOW USING THE MATRIX RATHER THAN THE DICTIONARY, HASHING STUFF HASN'T CHANGED YET\n",
        "\n",
        "    ###################\n",
        "    def check_hashing_matrix(self, matching_info, n):\n",
        "        t = 1\n",
        "        total = 0\n",
        "        for i in range(1, n + 1):\n",
        "            total = (total + t * matching_info[i]) % HASHING_TOTAL\n",
        "     #       print(total)\n",
        "            t = (t * HASHING_NUM) % HASHING_TOTAL\n",
        "    #    print(total)\n",
        "        if total in self.hashing_table:\n",
        "    #        print(total)\n",
        "            return False\n",
        "        else:\n",
        "      #      print(total)\n",
        "            self.hashing_table.add(total)\n",
        "            return True\n",
        "\n",
        "\n",
        "      \n",
        "    def GPU_search_update_results(self, cur_level, tmp_value, tmp_history, searching_history, searching_value):\n",
        "      nn = cp.size(tmp_value)\n",
        "      p = cp.argsort(tmp_value)[max(nn - SEARCH_RANGE, 0):nn]\n",
        "      nn = cp.size(p)\n",
        "      GPU_search_update_history_position[nn,1](cur_level, p, tmp_value, tmp_history, searching_history, searching_value, nn)\n",
        "      \n",
        "    def GPU_TRUST_clear_start_matrix(self, template_graph_size):\n",
        "        self.hashing_table = set()\n",
        "        self.searching_history = np.zeros([template_graph_size + 1, SEARCH_RANGE, 3], dtype=int)\n",
        "        self.searching_value = np.zeros([template_graph_size + 1, SEARCH_RANGE], dtype=float)\n",
        "\n",
        "    ### THIS IS THE MAIN GPU SEARCHING FUNCTION\n",
        "    def GPU_search_best_fitting_graph_matrix_type(self, template_graph):\n",
        "        self.GPU_TRUST_clear_start_matrix(template_graph.n)\n",
        "        # searching_history: [lvl, instance num, 3]\n",
        "        #                    where each instance = [father instance index, data_node_index, template_node_index]\n",
        "        # searching_history: Corresponding value of \"newest instance\"\n",
        "        # THE FATHER INDEX: WHERE THE INSTANCE COMING FROM.\n",
        "        #                   Say if we use instance searching_history[3][7(instance 7)] to update the searching_history[4][2] (using pair(A,a),\n",
        "        #                   Then searching_history[4][2][0] = 7,\n",
        "        #                        searching_history[4][2][1] = A,\n",
        "        #                        searching_history[4][2][2] = a\n",
        "\n",
        "   #     GPU_SEARCH_RANGE = cuda.to_device(SEARCH_RANGE)\n",
        "        GPU_one_hop_score_table = cp.array(self.one_hop_score_table)\n",
        "        GPU_template_graph_adj_matrix = cp.array(template_graph.adj_matrix)\n",
        "        GPU_data_graph_adj_matrix = cp.array(self.adj_matrix)\n",
        "        searching_history = cp.zeros([template_graph.n + 2, SEARCH_RANGE + 1, 3], dtype=int)\n",
        "        searching_value = cp.zeros([template_graph.n + 2, SEARCH_RANGE + 1], dtype=float)\n",
        "\n",
        "        tmp_value = np.zeros(SEARCH_RANGE * ADJ_MAX * template_graph.n + 1, dtype=float)\n",
        "        tmp_history = np.zeros((SEARCH_RANGE * ADJ_MAX * template_graph.n + 1, 3), dtype=int)\n",
        "\n",
        "        #for j in range(1, template_graph.n + 1):\n",
        "        j = 1\n",
        "        for i in range(1, self.n + 1):\n",
        "          tmp_value[(i - 1) * template_graph.n + j - 1] = self.one_hop_score_table[i][j]\n",
        "          tmp_history[(i - 1) * template_graph.n + j - 1] = (0, i, j)\n",
        "        tmp_value= cp.array(tmp_value, dtype = float)\n",
        "        tmp_history = cp.array(tmp_history, dtype = int)\n",
        "        #print(type(tmp_value))\n",
        "        #print(type(tmp_history))\n",
        "\n",
        "        self.GPU_search_update_results(1, tmp_value, tmp_history, searching_history, searching_value)\n",
        "\n",
        "        for current_lvl in range(1, template_graph.n):\n",
        "          # self.hashing_table = set()\n",
        "          GPU__trust_searching_matrix_type[SEARCH_RANGE,1](self.n, template_graph.n, current_lvl, GPU_one_hop_score_table, GPU_template_graph_adj_matrix, GPU_data_graph_adj_matrix, searching_history, searching_value, tmp_history, tmp_value)\n",
        "          #DATA_NODE_SIZE : int , TEMPLATE_NODE_SIZE : int ,current_lvl, GPU_one_hop_score_table, GPU_template_graph_adj_matrix, GPU_data_graph_adj_matrix,searching_history, searching_value, new_value, new_history\n",
        "         # print(cp.max(tmp_value))\n",
        "          self.GPU_search_update_results(current_lvl + 1, tmp_value, tmp_history, searching_history, searching_value)\n",
        "         # print(searching_history[current_lvl])\n",
        "         # print(searching_value[current_lvl])\n",
        "          \n",
        "        self.GPU_TRUST_output_result_matrix(template_graph.n, searching_value, searching_history)\n",
        "\n",
        "        \n",
        "    def GPU_TRUST_output_result_matrix(self, cur_level, searching_value, searching_history):\n",
        "        n = cur_level\n",
        "        print(\"PRINTING TOP K BEST SOLUTION....\")\n",
        "        cnt = 0\n",
        "        return\n",
        "        for searching_index in range(0, SEARCH_RANGE):\n",
        "            fa, x, y = searching_history[n][searching_index]\n",
        "            if x != 0 and y != 0:\n",
        "                cnt += 1\n",
        "                print(\"result No.\", cnt)\n",
        "                print(\"---Avg One-hop-value\", searching_value[n][searching_index] / n)\n",
        "                print(\"---Matching info(data node, template node):\")\n",
        "                if DETAIL_RESULT == True:\n",
        "                    for k in range(n - 1, 0, -1):\n",
        "                        print(x, y)\n",
        "                        fa, x, y = searching_history[k][fa]\n",
        "                    print(x, y)\n",
        "                #return\n",
        "\n",
        "    def output_adj_matrix(self):\n",
        "        print(self.n)\n",
        "        for i in range(1, self.n + 1):\n",
        "          print(self.adj_matrix[i][1 : self.adj_matrix[i][0] + 1])\n",
        "\n",
        "#build a graph\n",
        "def create_graph(size : int, edge_size : int) -> Graph:\n",
        "    #create node\n",
        "    node_list : List[Node] = []\n",
        "    node_size = size\n",
        "    for i in range(1, size + 1):\n",
        "        name = random.random()\n",
        "        new_node = Node(str(name), random.randint(0, 100))\n",
        "        node_list += [new_node]\n",
        "    #create edges\n",
        "    edge_list : List[Edge] = []\n",
        "    t = np.zeros((node_size, ADJ_MAX))\n",
        "    adj_num = np.zeros(node_size, dtype = int)\n",
        "    for j in range(1, edge_size + 1):\n",
        "        name = random.random()\n",
        "        p = q = 0\n",
        "        flag = True\n",
        "        while flag:\n",
        "          p = random.randint(0, size - 1)\n",
        "          q = random.randint(0, size - 1)\n",
        "          if (p == q or adj_num[p] >= ADJ_MAX or adj_num[q] >= ADJ_MAX):\n",
        "            continue\n",
        "          flag = False\n",
        "          for i in range(0, adj_num[p]):\n",
        "            if t[p][i] == q:\n",
        "              flag = True\n",
        "              break\n",
        "          for i in range(0, adj_num[q]):\n",
        "            if t[q][i] == p:\n",
        "              flag = True\n",
        "              break\n",
        "        t[p][adj_num[p]] = q\n",
        "        t[q][adj_num[q]] = p\n",
        "        adj_num[p] += 1\n",
        "        adj_num[q] += 1\n",
        "        new_edge = Edge(str(name), node_list[p].name, node_list[q].name, random.randint(0, 100))\n",
        "        edge_list += [new_edge]\n",
        "    return Graph(node_size, edge_size, node_list, edge_list)\n",
        "\n",
        "# variables to vary\n",
        "A = create_graph(10000, 40000)\n",
        "B = create_graph(3, 3)\n",
        "# change them according to excel table \n",
        "\n",
        "print(\"Building the similarity score\")\n",
        "time_0 = time.time()\n",
        "A.build_word_distance(B)\n",
        "time_A = time.time()\n",
        "print(\"SIMILARITY RUNNING TIME:\", time_A - time_0)\n",
        "\n",
        "print(\"Building the one hop score...Speeding_up(GPU)\")\n",
        "A.GPU_build_node_based_one_hop_score(B)\n",
        "time_B = time.time()\n",
        "print(\"Building Complete.\")\n",
        "print(\"ONE_HOP_SCORE RUNNING TIME:\", time_B - time_A)\n",
        "\n",
        "print(\"Building the one hop score...Speeding_up(CPU)\")\n",
        "#A.CPU_build_node_based_one_hop_score(B)\n",
        "A.OLD_build_node_based_one_hop_score(B)\n",
        "time_C = time.time()\n",
        "print(\"Building Complete.\")\n",
        "print(\"ONE_HOP_SCORE RUNNING TIME:\", time_C - time_B)\n",
        "\n",
        "print(\"Building the one hop score...(OLD)\")\n",
        "#A.GPU_build_node_based_one_hop_score(B)\n",
        "#A.OLD_build_node_based_one_hop_score(B)\n",
        "print(\"TOO SLOW SKIPPED\")\n",
        "time_D = time.time()\n",
        "\n",
        "print(\"Building Complete.\")\n",
        "print(\"ONE_HOP_SCORE RUNNING TIME:\", time_D - time_C)\n",
        "#print adj matrix and one-hop score matrixa\n",
        "#print(\"adj-matrix of data graph\", A.output_adj_matrix())\n",
        "#print(\"adj-matrix of template graph\", B.output_adj_matrix())\n",
        "print(\"One Hop Score Matrix:\\n\", A.one_hop_score_table[1:A.n + 1, 1:B.n + 1])\n",
        "#print(\"One Hop Score Matrix New:\\n\", A.one_hop_score_table_CPU[1:A.n + 1, 1:B.n + 1])\n",
        "\n",
        "print(\"Building the Trust Searching Tree...Using...GPU....\")\n",
        "# A.search_best_fitting_graph(B)\n",
        "#A.search_best_fitting_graph_matrix_type(B)\n",
        "A.GPU_search_best_fitting_graph_matrix_type(B)\n",
        "time_E = time.time()\n",
        "print(\"TRUST RUNNING TIME:\", time_E - time_D)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NctxhP0yfy2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1dbb36b-c285-4506-ede6-ccf1b4830bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0            b'Tesla K80'                              [SUPPORTED]\n",
            "                      compute capability: 3.7\n",
            "                           pci device id: 4\n",
            "                              pci bus id: 0\n",
            "Summary:\n",
            "\t1/1 devices are supported\n",
            "Building the similarity score\n",
            "SIMILARITY RUNNING TIME: 48.969730615615845\n",
            "Building the one hop score...Speeding_up(GPU)\n",
            "Building Complete.\n",
            "ONE_HOP_SCORE RUNNING TIME: 1.241767168045044\n",
            "Building the one hop score...Speeding_up(CPU)\n",
            "Building Complete.\n",
            "ONE_HOP_SCORE RUNNING TIME: 864.107602596283\n",
            "Building the one hop score...(OLD)\n",
            "TOO SLOW SKIPPED\n",
            "Building Complete.\n",
            "ONE_HOP_SCORE RUNNING TIME: 0.0022552013397216797\n",
            "One Hop Score Matrix:\n",
            " [[0.44722222 0.44722222 0.47222222]\n",
            " [0.4875731  0.54586988 0.46253655]\n",
            " [0.4494152  0.45263158 0.4494152 ]\n",
            " ...\n",
            " [0.51023392 0.47888239 0.50730994]\n",
            " [0.48099415 0.50268031 0.45004873]\n",
            " [0.65935673 0.6505848  0.61354776]]\n",
            "Building the Trust Searching Tree...Using...GPU....\n",
            "PRINTING TOP K BEST SOLUTION....\n",
            "TRUST RUNNING TIME: 1.3398094177246094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mPYm-McMz3Q",
        "outputId": "4aec7e0a-276b-4714-86d5-b32367ad5871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below is I alter the normal \"recurrsive\" max-matching algorithm to a non-recurrsive one.\n",
        "#I consider this edition pretty fun\n",
        "\n",
        "\n",
        "def max_matching_algo(w : np.array, n: int) -> float:\n",
        " #   print(\"matching....\")\n",
        "    lx = np.zeros([n + 2], dtype = float)\n",
        "    ly = np.zeros([n + 2], dtype = float)\n",
        "    visited_x = np.zeros([n + 2], dtype=int)\n",
        "    visited_y = np.zeros([n + 2], dtype=int)\n",
        "    link_y = np.zeros([n + 2], dtype=int)\n",
        "    global lack\n",
        "\n",
        "    def find(x: int) -> bool:\n",
        "        global lack\n",
        "        visited_x[x] = True\n",
        "        for y in range(1, n + 1):\n",
        "            if not visited_y[y]:\n",
        "                tmp = lx[x] + ly[y] - w[x][y]\n",
        "                if tmp < eps:\n",
        "                    visited_y[y] = True\n",
        "                    if link_y[y] == 0 or find(link_y[y]):\n",
        "                        link_y[y] = x\n",
        "                        return True\n",
        "                else:\n",
        "                    lack = min(lack, tmp)\n",
        "        return False\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            lx[i] = max(lx[i], w[i][j]) # init\n",
        "\n",
        "    for x in range(1, n + 1):\n",
        "        while True:\n",
        "            visited_x = np.zeros([n + 2], dtype=int)\n",
        "            visited_y = np.zeros([n + 2], dtype=int)\n",
        "            lack = 100000\n",
        "            if find(x): break\n",
        "            for i in range(1, n + 1):\n",
        "                if visited_x[i]:\n",
        "                    lx[i] -= lack\n",
        "                if visited_y[i]:\n",
        "                    ly[i] += lack\n",
        "    total_value = 0.\n",
        "\n",
        "    for y in range(1, n + 1):\n",
        "        total_value += w[link_y[y]][y]\n",
        "\n",
        "  #  print(\"matching Complete!\")\n",
        "    return total_value\n",
        "\n",
        "\n",
        "\n",
        "def GPU_max_matching_algo(w : np.array, n: int) -> float:\n",
        " #   print(\"matching....\")\n",
        "    lx = np.zeros([n + 2], dtype = float)\n",
        "    ly = np.zeros([n + 2], dtype = float)\n",
        "    visited_x = np.zeros([n + 2], dtype=int)\n",
        "    visited_y = np.zeros([n + 2], dtype=int)\n",
        "    link_y = np.zeros([n + 2], dtype=int)\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            lx[i] = max(lx[i], w[i][j]) # init\n",
        "\n",
        "    for x in range(1, n + 1):\n",
        "      while True:\n",
        "        lack_GPU = 100000\n",
        "        visited_x = np.zeros([n + 2], dtype=int)\n",
        "        visited_y = np.zeros([n + 2], dtype=int)\n",
        "\n",
        "        pos = 1\n",
        "        stack_x = np.zeros(n, dtype = int)\n",
        "        stack_y = np.zeros(n, dtype = int)\n",
        "        stack_x[1] = x\n",
        "        stack_y[1] = 0\n",
        "        Label = False\n",
        "        while pos > 0:\n",
        "          cur_x = stack_x[pos]\n",
        "          cur_y = stack_y[pos]\n",
        "          Recur_label = False\n",
        "          if Label:\n",
        "            link_y[cur_y] = cur_x\n",
        "            pos -= 1\n",
        "            continue\n",
        "          visited_x[cur_x] = True\n",
        "          for y in range(cur_y + 1, n + 1):\n",
        "            if not visited_y[y]:\n",
        "              tmp_GPU = lx[cur_x] + ly[y] - w[cur_x][y]\n",
        "              if tmp_GPU < eps:\n",
        "                  visited_y[y] = True\n",
        "                  if link_y[y] == 0:\n",
        "                    link_y[y] = cur_x\n",
        "                    pos -=1\n",
        "                    Label = True\n",
        "                  else:\n",
        "                    stack_y[pos] = y\n",
        "                    pos += 1\n",
        "                    stack_x[pos] = link_y[y]\n",
        "                    stack_y[pos] = 0\n",
        "                    Recur_label = True\n",
        "                  break\n",
        "              else:\n",
        "                  lack_GPU = min(lack_GPU, tmp_GPU)\n",
        "          if Recur_label == False and Label == False: pos -= 1\n",
        "\n",
        "        if Label: break\n",
        "\n",
        "        for i in range(1, n + 1):\n",
        "            if visited_x[i]:\n",
        "                lx[i] -= lack_GPU\n",
        "            if visited_y[i]:\n",
        "                ly[i] += lack_GPU\n",
        "    total_value = 0.\n",
        "\n",
        "    for y in range(1, n + 1):\n",
        "        total_value += w[link_y[y]][y]\n",
        "\n",
        "  #  print(\"matching Complete!\")\n",
        "    return total_value\n",
        "\n",
        "n = 105\n",
        "p = np.random.rand(n + 1, n + 1)\n",
        "output_B = GPU_max_matching_algo(p,n)\n",
        "output_A = max_matching_algo(p,n)\n",
        "output_C = GPU_max_matching_algo(p,n)\n",
        "print(output_A, output_B, output_C)"
      ],
      "metadata": {
        "id": "ggN2HZCvEczQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373e8932-ee31-42a0-c55d-27df3042d3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]\n",
            "103.41049129599283 103.41049129599283 103.41049129599283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtx5eRTjBYKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}